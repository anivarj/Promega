{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Ani Michaud\n",
    "Description: \n",
    "This script will import data from Glo-MAX readers and concatenate multiple plates into a single .csv file.\n",
    "Run the script, select your data location, and let it run!\n",
    "\n",
    "\n",
    "DEPENDENCIES:\n",
    "- Data MUST include .xlsx and .csv for metadata and raw data (respectively).\n",
    "- This script has not been tested on partially acquired plate setups, but theoretically should work.\n",
    "\n",
    "'''\n",
    "\n",
    "#import packages needed\n",
    "from genericpath import exists\n",
    "from operator import index\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tkinter.filedialog import askdirectory\n",
    "\n",
    "# Make a list of the xlsx files in the locations you specify\n",
    "def get_files(targetWorkspace):\n",
    "    origPaths = [] #future list of paths to all original files\n",
    "    filenames = [] #future list of file names\n",
    "\n",
    "    for dirpath, dirnames, files in os.walk(targetWorkspace):                   #Walks through targetWorkspace\n",
    "        files = [f for f in files if not f[0] == '.' and f.endswith('.xlsx')]   #Finds all xlsx files. Excludes hidden files in the files list\n",
    "        dirnames[:] = [d for d in dirnames if not d[0] == '.']                  #Excludes hidden directories in dirnames list\n",
    "\n",
    "        for file in files:                                   \n",
    "            filenames.append(file)                            #Append each file name to the filenames list\n",
    "            origPaths.append(os.path.join(dirpath, file))     #For each file, get the full path to it's location\n",
    "    return(origPaths) #returns a list of full paths to all xlsx files.\n",
    "\n",
    "#For a given xlsx file, parses metadata and stores it\n",
    "def importMetaData(file):\n",
    "    metadata_xlsx = pd.read_excel(file, \"Results\") #load the file and read the results tab\n",
    "\n",
    "    np_metadata = np.array(metadata_xlsx) #array from pandas dataframe\n",
    "\n",
    "    protocol = np_metadata[0,3] #location of protocol field\n",
    "    plateName = np_metadata[1,3] #location of plate name field\n",
    "    readout = np_metadata[5,0]  #location of readout (BRET or Luminesence)\n",
    "    emissionFilter = np_metadata[6,3] #location of emission filter info\n",
    "\n",
    "    if readout == \"BRET\":                   #if the readout is BRET, get the location of acceptor filter info and integration time\n",
    "        acceptorFilter = np_metadata[7,3]\n",
    "        integrationTime = np_metadata[8,3]\n",
    "    else:                                   #if the readout is luminescence, just get the integration time (no acceptor listed)\n",
    "        integrationTime = np_metadata[7,3]\n",
    "\n",
    "    #create a list of title:value pairs from the metadata\n",
    "    metadata = [[\"Protocol\", protocol], [\"Plate Name\",plateName], [\"Readout\" ,  readout], [\"Emission Filter\" ,   emissionFilter], [\"Integration Time\" ,    integrationTime]]\n",
    "\n",
    "    newDf = pd.DataFrame(metadata, columns = [\"Category\", \"Value\"]) #append the pairs to a dataframe\n",
    "    return(np_metadata, newDf) #return the dataframe and original metadata array (can probably eliminate np_metadata once comfortable with script functionability)\n",
    "\n",
    "#for a given xlsx file, finds the corresponding .csv and imports raw data\n",
    "def importCSV(file):\n",
    "    csvFile = file.rsplit(\".\",1)[0] + \".csv\"                                                        #take original file name and replace suffix with .csv\n",
    "    csvDf = pd.read_csv(csvFile, usecols=['WellPosition', 'Donor_RLU', 'Acceptor_RLU', 'Ratio'])    #read the csv file and extract the relevant columns\n",
    "    csvDf[['Row', 'Column']] = csvDf['WellPosition'].str.split(':', expand=True)                    #split the WellPosition column into two parts\n",
    "    csvDf['Column'] = csvDf['Column'].str.pad(width=2, side='left', fillchar= \"0\")                  #pad the well column numbers with 0s (01, 02...)\n",
    "    return(csvDf) #returns a dataframe with extracted data for all donor, acceptor and ratios\n",
    "\n",
    "#exctracts a single type of data (donor, acceptor or ratio) and reshuffles it to a classic plate layout\n",
    "def extract_data(csvDf, signal):\n",
    "    df = csvDf[['Row', 'Column', signal]].copy()                        #extract the relevant column to a dataframe\n",
    "    dfSorted = df.pivot(index='Row', columns='Column', values = signal) #pivots into a plate layout (rows = letters, columns = numbers)\n",
    "    dfSorted= dfSorted.reset_index(level=0)                             #resets the index\n",
    "    dfSorted.insert(0, column='Label', value=signal)                    #insert a label field for the data category\n",
    "    return(dfSorted) #returns the shuffled data\n",
    "\n",
    "\n",
    "###### MAIN FUNCTIONS BELOW #######\n",
    "###################################\n",
    "\n",
    "# Choose your raw data location\n",
    "targetWorkspace = askdirectory(title=\"SELECT YOUR DATA LOCATION\")\n",
    "concatFile = os.path.join(targetWorkspace, 'data-concat.csv') #location of the final concatenated file\n",
    "\n",
    "if os.path.exists(concatFile): #if the concat file already exists, delete it.\n",
    "    os.remove(concatFile)\n",
    "    print(\"output file already exists. deleting previous version\")\n",
    "\n",
    "paths = get_files(targetWorkspace) #list of path output from get_files\n",
    "\n",
    "#for each xlsx file in the paths list, do the following:\n",
    "for file in paths:\n",
    "    xlsxFile, metaData = importMetaData(file)   #import metadata into pandas dataframe\n",
    "    csvDf= importCSV(file)                      #load the csv file columns into a dataframe\n",
    "\n",
    "    donor = extract_data(csvDf, 'Donor_RLU')        #extract and re-shuffle the donor data\n",
    "    acceptor = extract_data(csvDf, 'Acceptor_RLU')  #extract and re-shuffle the acceptor data\n",
    "    ratio = extract_data(csvDf, 'Ratio')            #extract and re-shuffle the ratio data\n",
    "    list_of_dfs = [donor, acceptor, ratio]          #list of dataframes to concatenate\n",
    "    \n",
    "    #write the donor, accepetor and ratio to an excel file\n",
    "    with open(concatFile,'a') as f:\n",
    "        metaData.to_csv(f, index=False, header=False, line_terminator='\\n')\n",
    "        f.write('\\n')\n",
    "        for df in list_of_dfs:\n",
    "            df.to_csv(f, index=False, line_terminator='\\n')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008b8255ade682f29fc9e947ad9e1faf20dd98464455eb2bcfc03266de07defa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
